# NLP Project

**Round 1**

  •  Import the text, let’s call it as T (book that you have downloaded and in TxT format)

  • Perform simple text pre-processing steps — you may have to do the removal of
  running section / chapter names / remove the pictures / tables and so on. Explore T
  you will understand (you may have to see regular expressions to do this).
  
  • Tokenise T and Remove the stop words from T
  
  • Analyse the frequency distribution of tokens in T.
  
  • Create a word cloud on the Tokens in T
  
  • Do PoS Tagging for T using anyone of the four tag sets studied in the class and get
  the distribution of various tags.
  
  • Take the largest chapter, say C, of the book and create a bi-gram probability table for
  this chapter. For this you should not remove the stop words.
  
  • Take any chapter (other than C) and play the Shannon game – Play the fill-in the
  blanks game with the bi-gram probability learned from the previous step.
  
  • See how much accurate it is by comparing with the original sentence
